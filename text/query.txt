 Blog
The latest news from Google AI
The Language Interpretability Tool (LIT): Interactive Exploration and Analysis of NLP Models
Friday, November 20, 2020
Posted by James Wexler, Software Developer and Ian Tenney, Software Engineer, Google Research
As natural language processing (NLP) models become more powerful and are deployed in more real-world contexts, understanding their behavior is becoming increasingly critical. While advances in modeling have brought unprecedented performance on many NLP tasks, many research questions remain about not only the behavior of these models under domain shift and adversarial settings, but also their tendencies to behave according to social biases or shallow heuristics.
